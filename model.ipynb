{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MWPbXrLpNvSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2 -> 23.2.1\n",
            "[notice] To update, run: C:\\Users\\abina\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/ed/30/b97456e7063edac0e5a405128065f0cd2033adfe3716fb2256c186bd41d0/pandas-2.0.3-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached pandas-2.0.3-cp310-cp310-win_amd64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\abina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.24.2)\n",
            "Collecting matplotlib\n",
            "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/ff/1f/2b83c7acf453318a80dc619e99fc30a663b2c1fb18be3d358a96addfecd9/matplotlib-3.7.2-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached matplotlib-3.7.2-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n",
            "Collecting seaborn\n",
            "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "Collecting scikit-learn\n",
            "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/96/cf/a714a655266229b51eb2bda117f15275f12457887f165f3c1cc58ab502f1/scikit_learn-1.3.0-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached scikit_learn-1.3.0-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
            "Collecting xgboost\n",
            "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/75/dd/9afe0d9d0f61a5384c3932626a022e38c396a5d88e6f5345ad2f7b576747/xgboost-1.7.6-py3-none-win_amd64.whl.metadata\n",
            "  Using cached xgboost-1.7.6-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas)\n",
            "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/94/0a/5eb57dd395fade977786b2d2c98c2bee8234358794be44422fe58a719d42/contourpy-1.1.0-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached contourpy-1.1.0-cp310-cp310-win_amd64.whl.metadata (5.7 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/ed/a6/706455fe35b0ee4113024f9aa9d59697c00220b49763b039e9adc6cc5936/fonttools-4.41.1-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached fonttools-4.41.1-cp310-cp310-win_amd64.whl.metadata (153 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\abina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\abina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (9.5.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\abina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib) (3.0.7)\n",
            "Collecting scipy>=1.5.0 (from scikit-learn)\n",
            "  Obtaining dependency information for scipy>=1.5.0 from https://files.pythonhosted.org/packages/ce/e4/50b6fd4a2b65222424646abf17830904c9190bdd2c8daa7aeec083273903/scipy-1.11.1-cp310-cp310-win_amd64.whl.metadata\n",
            "  Using cached scipy-1.11.1-cp310-cp310-win_amd64.whl.metadata (59 kB)\n",
            "Collecting joblib>=1.1.1 (from scikit-learn)\n",
            "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/28/08/9dcdaa5aac4634e4c23af26d92121f7ce445c630efa0d3037881ae2407fb/joblib-1.3.1-py3-none-any.whl.metadata\n",
            "  Using cached joblib-1.3.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
            "  Using cached threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\abina\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Using cached pandas-2.0.3-cp310-cp310-win_amd64.whl (10.7 MB)\n",
            "Using cached matplotlib-3.7.2-cp310-cp310-win_amd64.whl (7.5 MB)\n",
            "Using cached scikit_learn-1.3.0-cp310-cp310-win_amd64.whl (9.2 MB)\n",
            "Using cached xgboost-1.7.6-py3-none-win_amd64.whl (70.9 MB)\n",
            "Using cached contourpy-1.1.0-cp310-cp310-win_amd64.whl (470 kB)\n",
            "Using cached fonttools-4.41.1-cp310-cp310-win_amd64.whl (2.1 MB)\n",
            "Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "Downloading scipy-1.11.1-cp310-cp310-win_amd64.whl (44.0 MB)\n",
            "   ---------------------------------------- 44.0/44.0 MB 3.0 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pytz, tzdata, threadpoolctl, scipy, kiwisolver, joblib, fonttools, cycler, contourpy, xgboost, scikit-learn, pandas, matplotlib, seaborn\n",
            "Successfully installed contourpy-1.1.0 cycler-0.11.0 fonttools-4.41.1 joblib-1.3.1 kiwisolver-1.4.4 matplotlib-3.7.2 pandas-2.0.3 pytz-2023.3 scikit-learn-1.3.0 scipy-1.11.1 seaborn-0.12.2 threadpoolctl-3.2.0 tzdata-2023.3 xgboost-1.7.6\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy matplotlib seaborn scikit-learn xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh25A9gnN2IG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOkebWYuPukx"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('mental-and-substance-use-as-share-of-disease.csv')\n",
        "df2 = pd.read_csv('prevalence-by-mental-and-substance-use-disorder.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8OCmhTlPuoK"
      },
      "outputs": [],
      "source": [
        "numeric_columns = df1.select_dtypes(include=[np.number]).columns\n",
        "df1[numeric_columns] = df1[numeric_columns].fillna(df1[numeric_columns].mean())\n",
        "\n",
        "numeric_columns = df2.select_dtypes(include=[np.number]).columns\n",
        "df2[numeric_columns] = df2[numeric_columns].fillna(df2[numeric_columns].mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBFpG3i9TeQf"
      },
      "outputs": [],
      "source": [
        "df1['DALYs (Disability-Adjusted Life Years) - Mental disorders - Sex: Both - Age: All Ages (Percent)'] = df1['DALYs (Disability-Adjusted Life Years) - Mental disorders - Sex: Both - Age: All Ages (Percent)'].astype(float)\n",
        "df2['Schizophrenia disorders (share of population) - Sex: Both - Age: Age-standardized'] = df2['Schizophrenia disorders (share of population) - Sex: Both - Age: Age-standardized'].astype(float)\n",
        "df2['Bipolar disorders (share of population) - Sex: Both - Age: Age-standardized'] = df2['Bipolar disorders (share of population) - Sex: Both - Age: Age-standardized'].astype(float)\n",
        "df2['Eating disorders (share of population) - Sex: Both - Age: Age-standardized'] = df2['Eating disorders (share of population) - Sex: Both - Age: Age-standardized'].astype(float)\n",
        "df2['Anxiety disorders (share of population) - Sex: Both - Age: Age-standardized'] = df2['Anxiety disorders (share of population) - Sex: Both - Age: Age-standardized'].astype(float)\n",
        "df2['Prevalence - Drug use disorders - Sex: Both - Age: Age-standardized (Percent)'] = df2['Prevalence - Drug use disorders - Sex: Both - Age: Age-standardized (Percent)'].astype(float)\n",
        "df2['Depressive disorders (share of population) - Sex: Both - Age: Age-standardized'] = df2['Depressive disorders (share of population) - Sex: Both - Age: Age-standardized'].astype(float)\n",
        "df2['Prevalence - Alcohol use disorders - Sex: Both - Age: Age-standardized (Percent)'] = df2['Prevalence - Alcohol use disorders - Sex: Both - Age: Age-standardized (Percent)'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es0OHT_PTeSo"
      },
      "outputs": [],
      "source": [
        "merged_df = pd.merge(df1, df2, on=['Entity', 'Code', 'Year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJF1IBAWTeVH"
      },
      "outputs": [],
      "source": [
        "X = merged_df[['Schizophrenia disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "               'Bipolar disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "               'Eating disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "               'Anxiety disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "               'Prevalence - Drug use disorders - Sex: Both - Age: Age-standardized (Percent)',\n",
        "               'Depressive disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "               'Prevalence - Alcohol use disorders - Sex: Both - Age: Age-standardized (Percent)']]\n",
        "\n",
        "y = merged_df['DALYs (Disability-Adjusted Life Years) - Mental disorders - Sex: Both - Age: All Ages (Percent)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8zhN4D9TeXG"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1p7f6pJTeY4"
      },
      "outputs": [],
      "source": [
        "# Compute the correlation matrix\n",
        "corr_matrix = merged_df[['Schizophrenia disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "                         'Bipolar disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "                         'Eating disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "                         'Anxiety disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "                         'Prevalence - Drug use disorders - Sex: Both - Age: Age-standardized (Percent)',\n",
        "                         'Depressive disorders (share of population) - Sex: Both - Age: Age-standardized',\n",
        "                         'Prevalence - Alcohol use disorders - Sex: Both - Age: Age-standardized (Percent)',\n",
        "                         'DALYs (Disability-Adjusted Life Years) - Mental disorders - Sex: Both - Age: All Ages (Percent)'\n",
        "                        ]].corr()\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap - Diseases and Mental Fitness')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVAV8SqwTea8"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmPZOocFTeck"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W8piPh9TeeO"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to store the model performance\n",
        "model_performance = {}\n",
        "\n",
        "# Ridge Regression\n",
        "ridge_model = Ridge(alpha=0.5)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "ridge_y_pred = ridge_model.predict(X_test)\n",
        "ridge_mse = mean_squared_error(y_test, ridge_y_pred)\n",
        "ridge_r2 = r2_score(y_test, ridge_y_pred)\n",
        "model_performance['1. Ridge Regression'] = {'MSE': ridge_mse, 'R-squared': ridge_r2}\n",
        "\n",
        "# Lasso Regression\n",
        "lasso_model = Lasso(alpha=0.5)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "lasso_y_pred = lasso_model.predict(X_test)\n",
        "lasso_mse = mean_squared_error(y_test, lasso_y_pred)\n",
        "lasso_r2 = r2_score(y_test, lasso_y_pred)\n",
        "model_performance['2. Lasso Regression'] = {'MSE': lasso_mse, 'R-squared': lasso_r2}\n",
        "\n",
        "# Elastic Net Regression\n",
        "elastic_net_model = ElasticNet(alpha=0.5, l1_ratio=0.5)\n",
        "elastic_net_model.fit(X_train, y_train)\n",
        "elastic_net_y_pred = elastic_net_model.predict(X_test)\n",
        "elastic_net_mse = mean_squared_error(y_test, elastic_net_y_pred)\n",
        "elastic_net_r2 = r2_score(y_test, elastic_net_y_pred)\n",
        "model_performance['3. Elastic Net Regression'] = {'MSE': elastic_net_mse, 'R-squared': elastic_net_r2}\n",
        "\n",
        "# Polynomial Regression\n",
        "poly_features = PolynomialFeatures(degree=2)\n",
        "X_poly = poly_features.fit_transform(X_train)\n",
        "poly_model = LinearRegression()\n",
        "poly_model.fit(X_poly, y_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "poly_y_pred = poly_model.predict(X_test_poly)\n",
        "poly_mse = mean_squared_error(y_test, poly_y_pred)\n",
        "poly_r2 = r2_score(y_test, poly_y_pred)\n",
        "model_performance['4. Polynomial Regression'] = {'MSE': poly_mse, 'R-squared': poly_r2}\n",
        "\n",
        "# Decision Tree Regression\n",
        "tree_model = DecisionTreeRegressor()\n",
        "tree_model.fit(X_train, y_train)\n",
        "tree_y_pred = tree_model.predict(X_test)\n",
        "tree_mse = mean_squared_error(y_test, tree_y_pred)\n",
        "tree_r2 = r2_score(y_test, tree_y_pred)\n",
        "model_performance['5. Decision Tree Regression'] = {'MSE': tree_mse, 'R-squared': tree_r2}\n",
        "\n",
        "# Random Forest Regression\n",
        "forest_model = RandomForestRegressor()\n",
        "forest_model.fit(X_train, y_train)\n",
        "forest_y_pred = forest_model.predict(X_test)\n",
        "forest_mse = mean_squared_error(y_test, forest_y_pred)\n",
        "forest_r2 = r2_score(y_test, forest_y_pred)\n",
        "model_performance['6. Random Forest Regression'] = {'MSE': forest_mse, 'R-squared': forest_r2}\n",
        "\n",
        "# SVR (Support Vector Regression)\n",
        "svr_model = SVR()\n",
        "svr_model.fit(X_train, y_train)\n",
        "svr_y_pred = svr_model.predict(X_test)\n",
        "svr_mse = mean_squared_error(y_test, svr_y_pred)\n",
        "svr_r2 = r2_score(y_test, svr_y_pred)\n",
        "model_performance['7. Support Vector Regression'] = {'MSE': svr_mse, 'R-squared': svr_r2}\n",
        "\n",
        "# XGBoost Regression\n",
        "xgb_model = XGBRegressor()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_y_pred = xgb_model.predict(X_test)\n",
        "xgb_mse = mean_squared_error(y_test, xgb_y_pred)\n",
        "xgb_r2 = r2_score(y_test, xgb_y_pred)\n",
        "model_performance['8. XGBoost Regression'] = {'MSE': xgb_mse, 'R-squared': xgb_r2}\n",
        "\n",
        "# K-Nearest Neighbors Regression\n",
        "knn_model = KNeighborsRegressor()\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_y_pred = knn_model.predict(X_test)\n",
        "knn_mse = mean_squared_error(y_test, knn_y_pred)\n",
        "knn_r2 = r2_score(y_test, knn_y_pred)\n",
        "model_performance['9. K-Nearest Neighbors Regression'] = {'MSE': knn_mse, 'R-squared': knn_r2}\n",
        "\n",
        "# Bayesian Regression\n",
        "bayesian_model = BayesianRidge()\n",
        "bayesian_model.fit(X_train, y_train)\n",
        "bayesian_y_pred = bayesian_model.predict(X_test)\n",
        "bayesian_mse = mean_squared_error(y_test, bayesian_y_pred)\n",
        "bayesian_r2 = r2_score(y_test, bayesian_y_pred)\n",
        "model_performance['10. Bayesian Regression'] = {'MSE': bayesian_mse, 'R-squared': bayesian_r2}\n",
        "\n",
        "# Neural Network Regression\n",
        "nn_model = MLPRegressor(max_iter=1000)\n",
        "nn_model.fit(X_train, y_train)\n",
        "nn_y_pred = nn_model.predict(X_test)\n",
        "nn_mse = mean_squared_error(y_test, nn_y_pred)\n",
        "nn_r2 = r2_score(y_test, nn_y_pred)\n",
        "model_performance['11. Neural Network Regression'] = {'MSE': nn_mse, 'R-squared': nn_r2}\n",
        "\n",
        "# Gradient Boosting Regression\n",
        "gb_model = GradientBoostingRegressor()\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_y_pred = gb_model.predict(X_test)\n",
        "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
        "gb_r2 = r2_score(y_test, gb_y_pred)\n",
        "model_performance['12. Gradient Boosting Regression'] = {'MSE': gb_mse, 'R-squared': gb_r2}\n",
        "\n",
        "# Print model performance\n",
        "for model, performance in model_performance.items():\n",
        "    print(f\"Model: {model}\")\n",
        "    print(\"   Mean Squared Error (MSE):\", performance['MSE'])\n",
        "    print(\"   R-squared Score:\", performance['R-squared'])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZLZH6bsTef1"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to store the model performance\n",
        "model_performance = {\n",
        "    'Ridge Regression': {'Predicted': ridge_y_pred, 'Actual': y_test},\n",
        "    'Lasso Regression': {'Predicted': lasso_y_pred, 'Actual': y_test},\n",
        "    'Elastic Net Regression': {'Predicted': elastic_net_y_pred, 'Actual': y_test},\n",
        "    'Polynomial Regression': {'Predicted': poly_y_pred, 'Actual': y_test},\n",
        "    'Decision Tree Regression': {'Predicted': tree_y_pred, 'Actual': y_test},\n",
        "    'Random Forest Regression': {'Predicted': forest_y_pred, 'Actual': y_test},\n",
        "    'Support Vector Regression': {'Predicted': svr_y_pred, 'Actual': y_test},\n",
        "    'XGBoost Regression': {'Predicted': xgb_y_pred, 'Actual': y_test},\n",
        "    'K-Nearest Neighbors Regression': {'Predicted': knn_y_pred, 'Actual': y_test},\n",
        "    'Bayesian Regression': {'Predicted': bayesian_y_pred, 'Actual': y_test},\n",
        "    'Neural Network Regression': {'Predicted': nn_y_pred, 'Actual': y_test},\n",
        "    'Gradient Boosting Regression': {'Predicted': gb_y_pred, 'Actual': y_test}\n",
        "}\n",
        "\n",
        "# Set up figure and axes\n",
        "num_models = len(model_performance)\n",
        "num_rows = (num_models // 3) + (1 if num_models % 3 != 0 else 0)\n",
        "fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 5))\n",
        "\n",
        "# Define color palette\n",
        "color_palette = plt.cm.Set1(range(num_models))\n",
        "\n",
        "# Iterate over the models and plot the predicted vs actual values\n",
        "for i, (model, performance) in enumerate(model_performance.items()):\n",
        "    row = i // 3\n",
        "    col = i % 3\n",
        "    ax = axes[row, col] if num_rows > 1 else axes[col]\n",
        "\n",
        "    # Get the predicted and actual values\n",
        "    y_pred = performance['Predicted']\n",
        "    y_actual = performance['Actual']\n",
        "\n",
        "    # Scatter plot of predicted vs actual values\n",
        "    ax.scatter(y_actual, y_pred, color=color_palette[i], alpha=0.5, marker='o')\n",
        "\n",
        "    # Add a diagonal line for reference\n",
        "    ax.plot([y_actual.min(), y_actual.max()], [y_actual.min(), y_actual.max()], color='r')\n",
        "\n",
        "    # Set the title and labels\n",
        "    ax.set_title(model)\n",
        "    ax.set_xlabel('Actual')\n",
        "    ax.set_ylabel('Predicted')\n",
        "\n",
        "    # Add gridlines\n",
        "    ax.grid(True)\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "fig.tight_layout()\n",
        "\n",
        "# Create a legend\n",
        "plt.legend(model_performance.keys(), loc='upper right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAZz0KfUTeiL"
      },
      "outputs": [],
      "source": [
        "# Store the regression models and their scores in a dictionary\n",
        "regression_scores = {\n",
        "    \"Ridge Regression\": (ridge_mse, ridge_r2),\n",
        "    \"Elastic Net Regression\": (elastic_net_mse, elastic_net_r2),\n",
        "    \"Polynomial Regression\": (poly_mse, poly_r2),\n",
        "    \"Random Forest Regression\": (forest_mse, forest_r2),\n",
        "    \"Gradient Boosting Regression\": (gb_mse, gb_r2),\n",
        "    \"Decision Tree Regression\": (tree_mse, tree_r2),\n",
        "    \"Lasso Regression\": (lasso_mse, lasso_r2),\n",
        "    \"Support Vector Regression\": (svr_mse, svr_r2),\n",
        "    \"XGBoost Regression\": (xgb_mse, xgb_r2),\n",
        "    \"K-Nearest Neighbors Regression\": (knn_mse, knn_r2),\n",
        "    \"Bayesian Regression\": (bayesian_mse, bayesian_r2),\n",
        "    \"Neural Network Regression\": (nn_mse, nn_r2),\n",
        "}\n",
        "\n",
        "# Sort the regression models based on MSE in ascending order and R-squared score in descending order\n",
        "sorted_models = sorted(regression_scores.items(), key=lambda x: (x[1][0], -x[1][1]))\n",
        "\n",
        "print(\"Regression Models in Order of Precision:\")\n",
        "for i, (model, scores) in enumerate(sorted_models, start=1):\n",
        "    print(f\"{i}. {model}\")\n",
        "    print(\"   Mean Squared Error (MSE):\", scores[0])\n",
        "    print(\"   R-squared Score:\", scores[1])\n",
        "    print()\n",
        "\n",
        "most_precise_model = sorted_models[0][0]\n",
        "least_precise_model = sorted_models[-1][0]\n",
        "\n",
        "print(f\"The most precise model is: {most_precise_model}\")\n",
        "print(f\"The least precise model is: {least_precise_model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-uq8xxRUYHM"
      },
      "source": [
        "# New Section"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
